{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fabeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea02c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(\n",
    "    \"./data/hair_classifier_v1.onnx\", providers=rt.get_available_providers()\n",
    ")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af201707",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fcbb7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the output is 'output'\n"
     ]
    }
   ],
   "source": [
    "print(f\"The name of the output is '{output_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6d56f",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131004af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b3e7d",
   "metadata": {},
   "source": [
    "We need to resize the image to 200x200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f190b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\"\n",
    "target_size = (200, 200)\n",
    "raw_image = download_image(url)\n",
    "image = prepare_image(raw_image, target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffb2aca",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b3453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_arr = np.asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517dddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(\n",
    "    image_arr: np.ndarray, means: np.ndarray, stds: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    # We must first convert from [0,255] to [0,1]  - transforms.ToTensor(),\n",
    "    # Now we normalize the data to zero mean and unit variance - transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    image_arr = image_arr / 255\n",
    "    return (image_arr - means) / stds\n",
    "\n",
    "\n",
    "means = np.array([0.485, 0.456, 0.406])\n",
    "stds = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_n = normalize_data(image_arr, means, stds).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed2671e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of the first pixel in the R channel is -1.073293924331665\n"
     ]
    }
   ],
   "source": [
    "print(f\"The value of the first pixel in the R channel is {image_n[0,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d87b641",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e19df0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input\n",
    "# Original: (200,200,3) in W,H,C\n",
    "# Then (1,200,200,3) in B,W,H,C\n",
    "# Final (1,3,200,200) in B,C,W,H\n",
    "image_input = image_n.reshape(1, 200, 200, 3).transpose(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa1e3d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.09156641]], dtype=float32)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([\"output\"], {\"input\": image_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26045ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
